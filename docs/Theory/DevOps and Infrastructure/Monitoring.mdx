---
title: Metrics
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

:::tip Definition
Software Engineering Metrics are quantitative signals used to measure, observe, and improve the health, performance, reliability, and delivery effectiveness of software systems and teams.

**Examples:**
- Service latency and error rates
- Deployment frequency and lead time
- Resource utilization and saturation
:::

It is primarily concerned with **making software systems and delivery processes observable, comparable, and improvable** through measurable data.

Typical examples include:
- Monitoring production system health and reliability
- Tracking delivery performance and engineering efficiency
- Detecting regressions, incidents, and capacity risks

---

## Benefit / What problem does it solve?

Using Software Engineering Metrics enables:

- Objective visibility into system behavior and engineering performance
- Early detection of incidents, bottlenecks, and degradation
- Data-driven decision making for reliability, scalability, and delivery improvements

---

## When to Use

**Use Software Engineering Metrics when:**

- You operate production systems that require reliability and uptime guarantees
- You need to understand system performance trends over time
- You want to improve engineering outcomes using measurable signals

**Typical examples:**

- Monitoring microservices running on Kubernetes
- Tracking SLOs and error budgets for critical services
- Measuring deployment frequency and incident recovery time

---

## When Not to Use

**Avoid Software Engineering Metrics when:**

- Metrics are collected without clear ownership or decision-making intent
- Vanity metrics replace outcome-focused signals
- Qualitative feedback is more appropriate than quantitative measurement

---

## Key Terminology & Definitions

- **Metric** – A numeric measurement collected over time (e.g. request latency)
- **Time Series** – A sequence of metric values indexed by time
- **Label / Dimension** – Key-value metadata used to slice and filter metrics
- **SLI (Service Level Indicator)** – A quantitative measure of service performance
- **SLO (Service Level Objective)** – A target value or range for an SLI
- **Error Budget** – The allowable amount of unreliability within an SLO

---

## Variants / Types

```mermaid
flowchart LR
    A[Application / Service] -->|Expose /metrics endpoint<br/>or use OpenTelemetry SDKs| B[Metrics Endpoint]

    B -->|Scrape (Pull Model)| C[Prometheus Collector]

    C -->|Write Time-Series Data| D[Prometheus TSDB]

    D -->|Query (PromQL)| E[Grafana]

    E -->|Dashboards & Visualisations| F[Engineers / Operators]
```

<Tabs>
<TabItem value="prometheus" label="Prometheus (Metrics Collection & Query)">

- **Key characteristics**
  - Pull-based metrics collection using exporters
  - Strong time-series data model with labels
  - Powerful query language (PromQL)
- **Example tools**
  - Prometheus, Alertmanager, exporters (node, kube-state, app exporters)
- **Primary purpose / benefit**
  - Reliable, scalable collection and querying of system and application metrics

</TabItem>

<TabItem value="grafana" label="Grafana (Visualization & Dashboards)">

- **Key characteristics**
  - Visualization-first, data-source agnostic
  - Supports metrics, logs, and traces
  - Strong dashboarding and alerting UX
- **Example tools**
  - Grafana, Grafana Alerting, Grafana OnCall
- **Primary purpose / benefit**
  - Human-friendly exploration, dashboards, and operational visibility

</TabItem>

<TabItem value="otel" label="OpenTelemetry (Instrumentation Standard)">

- **Key characteristics**
  - Vendor-neutral instrumentation APIs and SDKs
  - Unified model for metrics, logs, and traces
  - Push-based collection via collectors
- **Example tools**
  - OpenTelemetry SDKs, OpenTelemetry Collector
- **Primary purpose / benefit**
  - Consistent, portable instrumentation across services and platforms

</TabItem>

<TabItem value="saas" label="Managed Metrics Platforms (SaaS)">

- **Key characteristics**
  - Hosted, opinionated metric pipelines
  - Reduced operational overhead
  - Integrated alerting and visualization
- **Example tools**
  - Datadog, New Relic, Dynatrace, CloudWatch
- **Primary purpose / benefit**
  - Fast time-to-value without managing metric infrastructure

</TabItem>
</Tabs>


---

## Key Strategies

<Tabs>
<TabItem value="golden" label="Golden Signals Strategy">

- **Step or approach**
  - Track latency, traffic, errors, and saturation
- **Responsibility**
  - Platform, SRE, or infrastructure teams
- **Focus / goal**
  - Fast detection of user-impacting issues

</TabItem>

<TabItem value="slo" label="SLO-Driven Strategy">

- **Step or approach**
  - Define SLIs, set SLOs, and manage error budgets
- **Responsibility**
  - Shared between engineering, SRE, and product
- **Focus / goal**
  - Balance reliability with delivery velocity

</TabItem>
</Tabs>

---

## How to Interact With It

- **Access pattern:** Query-based (PromQL), dashboard-driven, alert-driven
- **Operations / Interfaces:** HTTP APIs, query languages, UIs, exporters, SDKs
- **Interaction model:**
  - Metrics scraped or pushed from services
  - Visualized via dashboards
  - Evaluated via alerting rules

---

## What Do Results Normally Look Like

- Time-series graphs (latency, throughput, error rates)
- Aggregated KPIs and SLO compliance views
- Alerts and notifications triggered by thresholds or burn rates

**Notes:**
Metrics require careful interpretation — aggregation, cardinality, and context matter. Metrics should always be paired with ownership and an explicit action model.
